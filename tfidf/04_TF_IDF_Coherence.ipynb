{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# TF-IDF Based Text Coherence Measurement\n",
                "\n",
                "This notebook measures text coherence using TF-IDF vectorization and cosine similarity between adjacent sentences.\n",
                "\n",
                "**Method:** TF-IDF (Term Frequency-Inverse Document Frequency)\n",
                "\n",
                "**4 Text Variants:**\n",
                "- Raw: Original sentences\n",
                "- Cleaned: Punctuation removed, lowercase\n",
                "- Stemmed: Zemberek morphological stemming\n",
                "- Cleaned + Stemmed: Both preprocessing steps"
            ],
            "metadata": {
                "id": "header"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Setup and Installation"
            ],
            "metadata": {
                "id": "setup"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install"
            },
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q -r requirements.txt\n",
                "\n",
                "import os\n",
                "\n",
                "# Download Zemberek JAR if not exists (for Google Colab)\n",
                "if not os.path.exists('zemberek-full.jar'):\n",
                "    !wget -q https://github.com/ahmetaa/zemberek-nlp/releases/download/v0.17.1/zemberek-full.jar\n",
                "    print(\"Downloaded zemberek-full.jar\")\n",
                "else:\n",
                "    print(\"zemberek-full.jar found\")\n",
                "\n",
                "# File paths (use absolute paths for JVM)\n",
                "ZEMBEREK_PATH = os.path.abspath('zemberek-full.jar')\n",
                "EXCEL_PATH = 'Text_Excel.xlsx'\n",
                "\n",
                "print(f\"Zemberek path: {ZEMBEREK_PATH}\")\n",
                "print(f\"File exists: {os.path.exists(ZEMBEREK_PATH)}\")"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "# Import libraries\n",
                "import jpype\n",
                "import jpype.imports\n",
                "from jpype import JClass\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "print(\"Libraries imported successfully\")"
            ],
            "metadata": {
                "id": "imports"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. Initialize Zemberek\n",
                "\n",
                "**⚠️ Important:** If you get a class not found error, restart the runtime (Runtime → Restart runtime) and run all cells again."
            ],
            "metadata": {
                "id": "zemberek_init"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Start JVM and load Zemberek\n",
                "# NOTE: JVM can only be started once per session. If you change the jar file,\n",
                "# you need to restart the runtime.\n",
                "\n",
                "if not jpype.isJVMStarted():\n",
                "    jpype.startJVM(classpath=[ZEMBEREK_PATH])\n",
                "    print(f\"JVM started with classpath: {ZEMBEREK_PATH}\")\n",
                "else:\n",
                "    print(\"JVM already running\")\n",
                "\n",
                "# Load Zemberek classes\n",
                "TurkishMorphology = JClass(\"zemberek.morphology.TurkishMorphology\")\n",
                "TurkishSentenceExtractor = JClass(\"zemberek.tokenization.TurkishSentenceExtractor\")\n",
                "\n",
                "morphology = TurkishMorphology.createWithDefaults()\n",
                "extractor = TurkishSentenceExtractor.DEFAULT\n",
                "\n",
                "print(\"Zemberek initialized successfully\")"
            ],
            "metadata": {
                "id": "zemberek"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Preprocessing Functions"
            ],
            "metadata": {
                "id": "preprocessing"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def extract_sentences(text):\n",
                "    \"\"\"Extract sentences from text using Zemberek.\"\"\"\n",
                "    sentences = extractor.fromParagraph(str(text)).toArray()\n",
                "    return [str(s).strip() for s in sentences if str(s).strip()]\n",
                "\n",
                "\n",
                "def clean_text(text):\n",
                "    \"\"\"Remove all punctuation and convert to lowercase.\"\"\"\n",
                "    return re.sub(r'[^\\w\\s]', '', text.lower().strip())\n",
                "\n",
                "\n",
                "def stem_sentence(sentence):\n",
                "    \"\"\"Extract word stems using Zemberek morphological analyzer.\"\"\"\n",
                "    try:\n",
                "        analysis = morphology.analyzeAndDisambiguate(sentence)\n",
                "        stems = [str(r.getStem()) for r in analysis.bestAnalysis()]\n",
                "        return \" \".join(stems)\n",
                "    except:\n",
                "        return sentence\n",
                "\n",
                "\n",
                "def get_text_variants(text):\n",
                "    \"\"\"\n",
                "    Generate 4 variants of the text:\n",
                "    - raw: original sentences\n",
                "    - cleaned: punctuation removed, lowercase\n",
                "    - stemmed: Zemberek stemming applied\n",
                "    - cleaned_stemmed: both cleaning and stemming\n",
                "    \"\"\"\n",
                "    sentences = extract_sentences(text)\n",
                "    \n",
                "    if len(sentences) < 2:\n",
                "        return None\n",
                "    \n",
                "    raw = sentences\n",
                "    cleaned = [clean_text(s) for s in sentences]\n",
                "    stemmed = [stem_sentence(s) for s in sentences]\n",
                "    cleaned_stemmed = [clean_text(stem_sentence(s)) for s in sentences]\n",
                "    \n",
                "    return {\n",
                "        'raw': raw,\n",
                "        'cleaned': cleaned,\n",
                "        'stemmed': stemmed,\n",
                "        'cleaned_stemmed': cleaned_stemmed\n",
                "    }\n",
                "\n",
                "print(\"Preprocessing functions defined\")"
            ],
            "metadata": {
                "id": "preprocess_funcs"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. TF-IDF Coherence Calculation"
            ],
            "metadata": {
                "id": "coherence_calc"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def calculate_adjacent_coherence(sentences):\n",
                "    \"\"\"\n",
                "    Calculate coherence as average cosine similarity between adjacent sentences\n",
                "    using TF-IDF vectorization.\n",
                "    \"\"\"\n",
                "    if len(sentences) < 2:\n",
                "        return None\n",
                "    \n",
                "    # Filter out empty sentences\n",
                "    sentences = [s for s in sentences if s.strip()]\n",
                "    if len(sentences) < 2:\n",
                "        return None\n",
                "    \n",
                "    try:\n",
                "        vectorizer = TfidfVectorizer()\n",
                "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
                "        \n",
                "        similarities = []\n",
                "        for i in range(len(sentences) - 1):\n",
                "            sim = cosine_similarity(tfidf_matrix[i], tfidf_matrix[i + 1])[0][0]\n",
                "            similarities.append(sim)\n",
                "        \n",
                "        return np.mean(similarities)\n",
                "    except:\n",
                "        return None\n",
                "\n",
                "print(\"Coherence calculation function defined\")"
            ],
            "metadata": {
                "id": "coherence_func"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. Load Data and Process"
            ],
            "metadata": {
                "id": "process"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Load Excel file (no header row)\n",
                "# Column A (index 0) = text numbers\n",
                "# Column B (index 1) = texts\n",
                "df = pd.read_excel(EXCEL_PATH, header=None)\n",
                "print(f\"Loaded {len(df)} texts\")\n",
                "\n",
                "# Get the second column (index 1) which contains the texts\n",
                "text_column = df.iloc[:, 1]\n",
                "print(f\"Processing {len(text_column)} texts from column B\")"
            ],
            "metadata": {
                "id": "load_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Process all texts\n",
                "results = []\n",
                "\n",
                "for idx, text in enumerate(text_column):\n",
                "    text_id = idx + 1\n",
                "    print(f\"Processing text {text_id}/{len(text_column)}...\", end=\"\\r\")\n",
                "    \n",
                "    variants = get_text_variants(str(text))\n",
                "    \n",
                "    if variants is None:\n",
                "        results.append({\n",
                "            'text_id': text_id,\n",
                "            'raw_coherence': None,\n",
                "            'cleaned_coherence': None,\n",
                "            'stemmed_coherence': None,\n",
                "            'cleaned_stemmed_coherence': None\n",
                "        })\n",
                "        continue\n",
                "    \n",
                "    results.append({\n",
                "        'text_id': text_id,\n",
                "        'raw_coherence': calculate_adjacent_coherence(variants['raw']),\n",
                "        'cleaned_coherence': calculate_adjacent_coherence(variants['cleaned']),\n",
                "        'stemmed_coherence': calculate_adjacent_coherence(variants['stemmed']),\n",
                "        'cleaned_stemmed_coherence': calculate_adjacent_coherence(variants['cleaned_stemmed'])\n",
                "    })\n",
                "\n",
                "print(f\"\\nProcessed {len(results)} texts successfully!\")"
            ],
            "metadata": {
                "id": "process_texts"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6. Save Results"
            ],
            "metadata": {
                "id": "save"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Create results DataFrame\n",
                "results_df = pd.DataFrame(results)\n",
                "\n",
                "# Display results\n",
                "print(\"\\n=== TF-IDF Coherence Results ===\")\n",
                "print(results_df.to_string(index=False))\n",
                "\n",
                "# Calculate averages\n",
                "print(\"\\n=== Average Coherence Scores ===\")\n",
                "print(f\"Raw:             {results_df['raw_coherence'].mean():.4f}\")\n",
                "print(f\"Cleaned:         {results_df['cleaned_coherence'].mean():.4f}\")\n",
                "print(f\"Stemmed:         {results_df['stemmed_coherence'].mean():.4f}\")\n",
                "print(f\"Cleaned+Stemmed: {results_df['cleaned_stemmed_coherence'].mean():.4f}\")"
            ],
            "metadata": {
                "id": "display_results"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Save to Excel\n",
                "OUTPUT_PATH = \"tfidf_coherence_results.xlsx\"\n",
                "results_df.to_excel(OUTPUT_PATH, index=False)\n",
                "print(f\"\\nResults saved to: {OUTPUT_PATH}\")"
            ],
            "metadata": {
                "id": "save_excel"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}